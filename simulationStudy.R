#----------------------------------------------------------------#
# Code to implement the simulation with data generated by        #
# RE model in paper                                              #
# Bayesian outcome selection modelling                           #
#----------------------------------------------------------------#
#library(blavaan)
library(coda)
library(tidyr)
library(rjags)
library(tidyr)
library(dplyr)
library(rstan)
#----------_#
##### modified version that incorporates the mixture distribution on the betas #####################

outputDir = "/Users/khuedung/Documents/outcome selection output/"

# First create some new functions
find_mean_selective <- function(betamatrix,meanprob,indmatrix){
  K = length(meanprob)
  mean_beta_selective = rep(NA,K)
  for(k in 1:K){
    if(meanprob[k] >0.5){
      mean_beta_selective[k] = mean(betamatrix[which(indmatrix[,k]==1),k])
    }else{
      mean_beta_selective[k]  = 0
    }
  }
  return(mean_beta_selective)
}
checkifBeta0in = function(CI,beta0){
  cond = 0
  if(CI[1]>beta0 || CI[2]<beta0){cond = 1}
  return(cond)
}
find_not_relevant= function(betamat,level = 0.95){
  ifrelevant = rep(NA,ncol(betamat))
  lb = (1-level)/2; ub = 1- (1-level)/2
  temp = apply(betamat,2,quantile,probs = c(lb,ub))
  checkvec = apply(temp,2,checkifBeta0in,beta0 =0)
  return(checkvec)
}

#------------------------#
nsim = 10
n = 100
mu_true =  -3# -0.1 #
tau  = 0.1*abs(mu_true)
K = 20
K1_list = c(5,10,15)

intercept = rnorm(K,0,1)
sdseq = rnorm(K,1.5,0.3)
varseq = c(paste0('y',seq(1,K)))
ind_effect = rnorm(n,0,1.2)

numRelevant = numCorrect= numFalsePositive = array(NA,dim = c(length(K1_list),nsim))
mukeep= array(NA,dim = c(length(K1_list),nsim))
mu_sub= mu_noselection = array(NA,dim = c(length(K1_list),nsim))
numRelevant_mu0 = numCorrect_mu0 = numFalsePositive_mu0 = array(NA, dim = c(length(K1_list),nsim))
numRelevant_laplace = numCorrect_laplace = numFalsePositive_laplace = array(NA, dim = c(length(K1_list),nsim))
beta_keep =  vector('list',length(K1_list))


mse_keep = array(NA,dim = c(length(K1_list),nsim))
mse_noselection = array(NA,dim = c(length(K1_list),nsim))
mse_mu0 = mse_laplace = array(NA,dim = c(length(K1_list),nsim))

tauest_keep = array(NA,dim = c(length(K1_list),nsim))
tauest_noselection = array(NA,dim = c(length(K1_list),nsim))
tauest_mu0 = array(NA,dim = c(length(K1_list),nsim))

# set prior values
precision_prior_intercept = 1/100
precision_prior_logsigma = 1/10
precision_prior_gamma = 1/100
precision_prior_logsigmaAlpha = 1/10
precision_prior_logtau = 1
precision_prior_mu = 1/100

mean_mu = 0
sd_mu = sqrt(1/precision_prior_mu)
sigma_prior_intercept = sqrt(1/precision_prior_intercept)
sigma_prior_logtau = sqrt(1/precision_prior_logtau)
sigma_prior_logsigma = sqrt(1/precision_prior_logsigma)
sigma_prior_logsigmaAlpha = sqrt(1/precision_prior_logsigmaAlpha)
sigma_prior_gamma = sqrt(1/precision_prior_gamma);

for(iter in 1:length(K1_list)){
  K1 = K1_list[iter]
  K2 = K- K1
  
  alpha_k = rep(0,K)
  alpha_k[1:K1] = mu_true + rnorm(K1,0,tau) # \tau = 1
  
  beta_keep[[iter]] = alpha_k
  
  varStatus = c(rep(1,K1),rep(0,K2))
  
  for(sim in 1:nsim){
    cat("simulation number: ",sim, " nRelevant = ", K1,"\n")
    pscore = rnorm(n) # z
    
    x= rep(NA,n) # exposure
    for(i in 1:n){
      x[i] = ifelse(pscore[i]<0,rnorm(1,0,0.5),rnorm(1,1,1))
    }
    
    data1 = array(NA,dim = c(n,K+1))
    data1[,(K+1)] = x
    
    
    for(k in 1:K){
      if(k<=K1){
        data1[,k] = ind_effect + intercept[k] + (alpha_k[k])*x + rnorm(1,0.1,0.02)*pscore + rnorm(n,0,sdseq[k])
      }else{
        data1[,k] = ind_effect  + intercept[k] + rnorm(1,0.1,0.02)*pscore + rnorm(n,0,sdseq[k])
      }
      
    }
    data1 = as.data.frame(cbind(data1,pscore))
    names(data1) = c(paste0('y',seq(1,K)),'x','pscore')
    
    #-------------------------------------#
    data_for_jags = list(N=nrow(data1), fullData=data1[,varseq], 
                         x = data1[,'x'], pscore = data1[,'pscore'],
                         K = K,pSignificant = c(rep(0.5,K )), g = 100,
                         precision_prior_intercept = precision_prior_intercept,
                         precision_prior_logsigma = precision_prior_logsigma,
                         precision_prior_gamma = precision_prior_gamma,
                         precision_prior_logsigmaAlpha = precision_prior_logsigmaAlpha, 
                         precision_prior_logtau= precision_prior_logtau,
                         precision_prior_mu = precision_prior_mu)
    
    model.fit.fixRatio <- jags.model(file="m3_indp.txt",
                                     data=data_for_jags,
                                     n.chains = 2)
    update(model.fit.fixRatio, 50000)
    model.samples.fixRatio <- coda.samples(model.fit.fixRatio, c("beta", "logsigma",  "intercept", "Ind","mu",'logtau','logsigma_alpha'), n.iter=50000,thin =10)
    
    parmcmc_matrix = as.data.frame(as.matrix(model.samples.fixRatio))
    indmat = dplyr::select(parmcmc_matrix,starts_with('Ind'))
    ifRelevant = rep(NA,K)
    for(k in 1:K){
      ifRelevant[k] = ifelse(mean(indmat[,k])>0.5,1,0)
    }
    numRelevant[iter,sim] = sum(ifRelevant)
    numCorrect[iter,sim]= sum(ifRelevant[1:K1])
    numFalsePositive[iter,sim] = sum(ifRelevant[(K1+1):K]-varStatus[(K1+1):K])
    mukeep[iter,sim] = mean(parmcmc_matrix$mu)
    
    beta_mat = dplyr::select(parmcmc_matrix,starts_with('beta'))
    meanPr = colMeans(indmat)
    mean_beta_selective <- find_mean_selective(beta_mat,meanPr,indmat)
    
    mse_keep[iter,sim] <- sum((mean_beta_selective-beta_keep[[iter]])^2)/K
    tauest_keep[iter,sim] = mean(exp(parmcmc_matrix[,'logtau']))
  
    #-----------------_#
    # no selection, other representation
    x_mat= array(NA,dim = c(nrow(data1),K,K))
    for(i in 1:nrow(data1)){
      x_mat[i,,] = diag(rep(data1[i,'x'],K))
    }
    data_to_fit_stan = list(N = n, K = K,y_all = data1[,varseq],x_mat = x_mat,
                          pscore = data1[,'pscore'], mean_mu = 0,sd_mu = 10,
                          n_missing= 0, n_complete = n, n_obs = 0,
                          missingRow = rep(0,0), missingCol = rep(0,0),
                          obsRow = rep(0,0),obsCol = rep(0,0), mean_mu = mean_mu,
                          sd_mu = sd_mu, sigma_prior_intercept = sigma_prior_intercept,
                          sigma_prior_logtau = sigma_prior_logtau, 
                          sigma_prior_logsigma = sigma_prior_logsigma,
                          sigma_prior_logsigmaAlpha = sigma_prior_logsigmaAlpha,
                          sigma_prior_gamma = sigma_prior_gamma ) 
    
    m3_RE_noselection = stan(file = 'model3_RE_MI_noselection.stan',data = data_to_fit_stan,iter=5000,warmup = 2500,
                             chains = 2,algorithm = 'NUTS',control = list(adapt_delta = 0.85)) #
    parmcmc_matrix = as.matrix(m3_RE_noselection,par = 'mu')
    mu_noselection[iter,sim] = mean(parmcmc_matrix)
    beta_mean_noselect = colMeans(as.matrix(m3_RE_noselection,pars = 'beta'))
    mse_noselection[iter,sim] = sum((beta_mean_noselect-beta_keep[[iter]])^2)/K
    tauest_noselection[iter,sim] = mean(as.matrix(m3_RE_noselection,par = 'tau'))
    
    #----------------------------------------------------#
    # Laplace prior
    m3_RE_laplace = stan(file = 'model3_RE_laplace.stan',data = data_to_fit_stan,iter=5000,warmup = 2500,
                         chains = 2,algorithm = 'NUTS',control = list(adapt_delta = 0.85)) #
    ifRelevant_laplace = find_not_relevant(as.matrix(m3_RE_laplace,pars = 'beta'))
    beta_mean_laplace = colMeans(as.matrix(m3_RE_laplace,pars = 'beta'))
    beta_mean_laplace[ifRelevant_laplace==0] = 0
    mse_laplace[iter,sim] = sum((beta_mean_laplace-beta_keep[[iter]])^2)/K
    numRelevant_laplace[iter,sim] = sum(ifRelevant_laplace)
    numCorrect_laplace[iter,sim]= sum(ifRelevant_laplace[1:K1])
    numFalsePositive_laplace[iter,sim] = sum(ifRelevant_laplace[(K1+1):K]-varStatus[(K1+1):K])
    #-----------------------------------------------------#
    # mu = 0
    model2.nomu.indp <- jags.model(file="m3_indp_mu0.txt",
                                   data=data_for_jags,
                                   n.chains = 2)
    
    update(model2.nomu.indp, 50000)
    model2.samples.nomu.indp <- coda.samples(model2.nomu.indp, c("beta", "logsigma", "Ind",'logtau'), n.iter=50000)
    parmcmc_matrix = as.data.frame(as.matrix(model2.samples.nomu.indp))
    indmat = dplyr::select(parmcmc_matrix,starts_with('Ind'))
    ifRelevant = rep(NA,K)
    for(k in 1:K){
      ifRelevant[k] = ifelse(mean(indmat[,k])>0.5,1,0)
    }
    numRelevant_mu0[iter,sim] = sum(ifRelevant)
    numCorrect_mu0[iter,sim]= sum(ifRelevant[1:K1])
    numFalsePositive_mu0[iter,sim] = sum(ifRelevant[(K1+1):K]-varStatus[(K1+1):K])
    
    beta_mat = dplyr::select(parmcmc_matrix,starts_with('beta'))
    meanPr = colMeans(indmat)
    mean_beta_selective <- find_mean_selective(beta_mat,meanPr,indmat)
    
    mse_mu0[iter,sim] <- sum((mean_beta_selective-beta_keep[[iter]])^2)/K
    tauest_mu0[iter,sim] = mean(exp(parmcmc_matrix[,'logtau']))
    
    #----------------------------------------------#
    # sub model
    if(K1>2){
      varInclude = seq(1,K1)
      allVarSub = varseq[varInclude]
      data_final_sub = data1[,c(allVarSub,'pscore','x')]
      
      x_mat_sub= array(NA,dim = c(nrow(data_final_sub),length(allVarSub),length(allVarSub)))
      for(i in 1:nrow(data_final_sub)){
        x_mat_sub[i,,] = diag(rep(data_final_sub[i,'x'],length(allVarSub)))
      }
      #
      data_to_fit_sub = list(N = nrow(data_final_sub), K = length(varInclude),
                             y_all = data_final_sub[,allVarSub],x_mat = x_mat_sub,
                             pscore = data_final_sub[,'pscore'], mean_mu =0, sd_mu = 10,
                             n_missing= 0, n_complete = n, n_obs = 0,
                             missingRow = rep(0,0), missingCol = rep(0,0),
                             obsRow = rep(0,0),obsCol = rep(0,0), mean_mu = mean_mu,
                             sd_mu = sd_mu, sigma_prior_intercept = sigma_prior_intercept,
                             sigma_prior_logtau = sigma_prior_logtau, 
                             sigma_prior_logsigma = sigma_prior_logsigma,
                             sigma_prior_logsigmaAlpha = sigma_prior_logsigmaAlpha,
                             sigma_prior_gamma = sigma_prior_gamma  )
      m3_RE_noselection_sub= stan(file = 'model3_RE_MI_noselection.stan',data = data_to_fit_sub,iter=5000,warmup = 2500,
                                  chains = 2,algorithm = 'NUTS',control = list(adapt_delta = 0.85),include = TRUE) #
      parmcmc_matrix = as.matrix(m3_RE_noselection_sub,par = 'mu')
      mu_sub[iter,sim] = mean(parmcmc_matrix)
    }
    # save temporary result
    save(n,K,mu_true,K1_list, beta_keep, sdseq,tauest_keep, mse_keep,
         numRelevant,numCorrect,numFalsePositive,mukeep,
         numRelevant_mu0,numCorrect_mu0,numFalsePositive_mu0, tauest_mu0,mse_mu0,
         mu_noselection,mse_noselection, tauest_noselection,
         numRelevant_laplace, numCorrect_laplace,numFalsePositive_laplace,mse_laplace,
         mu_sub,file = paste0(outputDir,'simulationRE_2023_largemu_test.RData')) 
  } # end one scenario
  cat("average no. relevant for K1 =: ",K1, " is  ",mean(numRelevant[iter,]) ,"\n")
}
